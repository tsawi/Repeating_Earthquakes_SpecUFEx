{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station BSG - SpecUFEx workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################\n",
    "##   I. Import waveforms, save to H5\n",
    "##  II. Convert to spectrograms, save to H5\n",
    "## III. Run specufex, save fingerprints to H5\n",
    "###################################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import obspy\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "import glob\n",
    "import datetime\n",
    "from f1_spectrogram_functions import wf_to_H5, gen_sgram_QC_noAlias\n",
    "\n",
    "sys.path.append('./specufex/specufex/')\n",
    "from specufex import BayesianNonparametricNMF, BayesianHMM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From previous notebook\n",
    "cat_region = pd.read_csv('../data/catalogs/NCADDiff_5km_2019_500mFault_WS21.csv')\n",
    "evID_region = cat_region.event_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###################################\n",
    "## Build paths and load settings\n",
    "###################################\n",
    "\n",
    "\n",
    "plot = 0   # plot spectrograms?\n",
    "mod = 2000 # Print 1 spectrogram for every %mod spectrograms generated \n",
    "\n",
    "yamlPath = \"./SA_REQS_BSG.yaml\"\n",
    "with open(yamlPath) as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    \n",
    "path_config = config[\"paths\"]\n",
    "key = path_config[\"key\"]\n",
    "data_config = config['dataParams']\n",
    "station = data_config[\"station\"]\n",
    "channel = data_config[\"channel\"]\n",
    "channel_ID = data_config[\"channel_ID\"]\n",
    "sampling_rate = data_config[\"sampling_rate\"]\n",
    "\n",
    "# build path strings\n",
    "dataH5_name = f'data_{key}.h5'\n",
    "projectPath = path_config[\"projectPath\"]\n",
    "pathCatFold = path_config[\"pathCatFold\"]\n",
    "\n",
    "\n",
    "# pathWF = path_config[\"pathWF\"]\n",
    "pathWF = '/Users/theresasawi/Documents/11_Manuscripts/SA_REQS/data/raw/BSG/'\n",
    "\n",
    "\n",
    "wf_cat_out_path = projectPath + f'{key}_wf_cat_out.csv'\n",
    "\n",
    "if not os.path.isdir(projectPath + 'data/H5files/'):\n",
    "    os.mkdir(projectPath + 'data/H5files/')\n",
    "    \n",
    "dataH5_path = projectPath + 'data/H5files/' + dataH5_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example evID:  72354471\n",
      "100.0  Hz;  2000  samples 51442 waveforms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "################################################\n",
    "## Create catalog with event ids made from filenames \n",
    "################################################\n",
    "wf_list = glob.glob(pathWF + '*')\n",
    "\n",
    "filenames = [path.split('/')[-1] for path in wf_list]\n",
    "    \n",
    "\n",
    "ev_ID = [int(path.split('/')[-1].split('.')[-1]) for path in wf_list]\n",
    "\n",
    "print('Example evID: ', ev_ID[0])\n",
    "cat_paths = pd.DataFrame({\"ev_ID\":ev_ID,\n",
    "                          \"event_ID\":ev_ID,\n",
    "                          \"filename\":filenames})\n",
    "\n",
    "\n",
    "wf_test = obspy.read(pathWF + cat_paths.filename.iloc[0])\n",
    "\n",
    "lenData = len(wf_test[channel_ID])\n",
    "sr = fs = wf_test[channel_ID].stats.sampling_rate\n",
    "\n",
    "print(sr, \" Hz; \", lenData, \" samples\", len(filenames), 'waveforms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_paths_region = cat_paths[cat_paths.event_ID.isin(evID_region)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################\n",
    "## Set spectrogram parameters\n",
    "###################################\n",
    "\n",
    "sgram_config = config[\"sgramParams\"]\n",
    "nfft = sgram_config[\"nfft\"]\n",
    "fmin, fmax = sgram_config[\"fmin\"], sgram_config[\"fmax\"]\n",
    "tmin, tmax = sgram_config[\"tmin\"], sgram_config[\"tmax\"]\n",
    "\n",
    "SpecUFEx_H5_name = 'SpecUFEx_' + path_config[\"h5name\"] #f'SpecUFEx_{key}.hdf5'\n",
    "SpecUFEx_H5_path = projectPath + 'data/H5files/' + SpecUFEx_H5_name\n",
    "\n",
    "\n",
    "##spectrogram parameters, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html\n",
    "nperseg = int(sgram_config[\"winLen_Sec\"]*fs) #datapoints per window segment\n",
    "noverlap = int(nperseg*sgram_config[\"fracOverlap\"])  #fraction of window overlapped  \n",
    "\n",
    "#padding must be longer than n per window segment\n",
    "if nfft < nperseg:\n",
    "    nfft = nperseg*2\n",
    "    print(\"nfft too short; changing to \", nfft)\n",
    "\n",
    "mode='magnitude'\n",
    "scaling='spectrum'\n",
    "\n",
    "# set args for generator\n",
    "args = {'station':station,\n",
    "        'channel':channel,\n",
    "        'fs': fs,\n",
    "        'lenData': lenData,\n",
    "        'nperseg': nperseg,\n",
    "        'noverlap': noverlap,\n",
    "        'nfft': nfft,\n",
    "        'mode': mode,\n",
    "        'scaling': scaling,\n",
    "        'fmin': fmin,\n",
    "        'fmax': fmax,\n",
    "        'tmin':tmin,\n",
    "        'tmax':tmax}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000 / 3640\n",
      "0  duplicate events found and avoided\n",
      "3637  waveforms loaded\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "## Save waveforms to H5\n",
    "###################################\n",
    "\n",
    "evID_keep, wf_example = wf_to_H5(projectPath,dataH5_path,pathWF,cat_paths_region,lenData,channel_ID,station,channel,t0=0,t1=10000000000, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3637"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evID_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/H5files/data_SA_REQS_BSG.h5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataH5_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save processing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "## Save processing information to data H5\n",
    "###################################\n",
    "with h5py.File(dataH5_path,'a') as h5file:\n",
    "    processing_group = h5file.create_group(f\"{station}/processing_info\")\n",
    "    processing_group.create_dataset(name= \"sampling_rate_Hz\", data=sampling_rate)#,dtype='S')\n",
    "    # processing_group.create_dataset(name= \"station_info\", data=station_info)\n",
    "    # processing_group.create_dataset(name= \"calibration\", data=calib)#,dtype='S')\n",
    "    # processing_group.create_dataset(name= \"orig_formata\", data=_format)#,dtype='S')\n",
    "    # processing_group.create_dataset(name= \"instr_response\", data=instr_response,dtype='S')\n",
    "    processing_group.create_dataset(name= \"lenData\", data=lenData)#,dtype='S')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 3637\n",
      "1000 / 3637\n",
      "2000 / 3637\n",
      "3000 / 3637\n",
      "N events in evID_list_QC_sgram: 3637\n",
      "N events in evID_BADones: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######################################################\n",
    "## Instantiate generator and generate spectrograms\n",
    "######################################################\n",
    "\n",
    "\n",
    "trim = True\n",
    "\n",
    "# put sgrams in h5\n",
    "gen_sgram = gen_sgram_QC_noAlias(5,key,\n",
    "                        evID_list=evID_keep,\n",
    "                        dataH5_path = dataH5_path,#h5 data file\n",
    "                        h5File=SpecUFEx_H5_path, #h5 sgram file\n",
    "                        trim=trim, #trim to min and max freq\n",
    "                        saveMat=False, #set true to save folder of .mat files\n",
    "                        sgramOutfile='.', #path to save .mat files\n",
    "                        **args\n",
    "                        ) #path to save sgram figures\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################\n",
    "## Part 2: Make spectrograms\n",
    "######################################################\n",
    "    \n",
    "evID_list_QC_sgram = []\n",
    "spectra_for_avg = []\n",
    "\n",
    "less10=0\n",
    "with h5py.File(SpecUFEx_H5_path,'a') as fileLoad:\n",
    "\n",
    "    n=0\n",
    "    Nkept=0\n",
    "\n",
    "    if 'spectrograms' in fileLoad.keys():\n",
    "        del fileLoad[\"spectrograms\"]\n",
    "\n",
    "    if 'sgram_normConst' in fileLoad.keys():\n",
    "        del fileLoad[\"sgram_normConst\"]\n",
    "\n",
    "    spectrograms_group     = fileLoad.create_group(f\"spectrograms\")\n",
    "\n",
    "    sgram_normConst_group  = fileLoad.create_group(f\"sgram_normConst\")\n",
    "\n",
    "    lenEv = len(evID_keep)\n",
    "    \n",
    "    while n <= lenEv: ## not sure a better way to execute this? But it works\n",
    "        try:   #catch generator \"stop iteration\" error\n",
    "            evID,sgram,fSTFT,tSTFT, normConstant, Nkept,evID_BADones, i = next(gen_sgram) #next() command updates generator\n",
    "             \n",
    "            n = i+1\n",
    "            evID = str(evID)\n",
    "            \n",
    "\n",
    "            if not evID in spectrograms_group:\n",
    "                \n",
    "                if np.max(sgram)>10: #v8 values below this were typically from bad stations \n",
    "                    \n",
    "                    spectrograms_group.create_dataset(name= evID, data=sgram)\n",
    "                    evID_list_QC_sgram.append(np.int64(evID))\n",
    "                    spectra_for_avg.append(np.array(sgram))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if not evID in sgram_normConst_group:\n",
    "                        \n",
    "                        sgram_normConst_group.create_dataset(name= evID, data=normConstant)\n",
    "#                 else:\n",
    "#                     print(\"dB less than 20\")\n",
    "                    \n",
    "\n",
    "                    if plot:\n",
    "\n",
    "                        if n%mod==0:\n",
    "                            plt.figure()\n",
    "                            plt.pcolormesh(tSTFT,fSTFT,sgram,shading='auto')\n",
    "                            cbar = plt.colorbar(pad=.06)\n",
    "                            cbar.set_label('dB',labelpad=8)#,fontsize = 14)\n",
    "                        #     plt.clim(0,45)\n",
    "                            plt.xlabel('time (s)')\n",
    "                            plt.ylabel('frequency (Hz)')\n",
    "                            plt.show()\n",
    "                else:\n",
    "                    less10 +=1\n",
    "                    \n",
    "\n",
    "        except StopIteration: #handle generator error\n",
    "            break\n",
    "\n",
    "    print('N events in evID_list_QC_sgram:', len(evID_list_QC_sgram))\n",
    "    print('N events in evID_BADones:', len(evID_BADones))\n",
    "\n",
    "    if 'spec_parameters' in fileLoad.keys():\n",
    "        del fileLoad[\"spec_parameters\"]\n",
    "        \n",
    "\n",
    "cat_final = cat_paths[cat_paths.event_ID.isin(evID_list_QC_sgram)]\n",
    "cat_final.to_csv(pathCatFold + f'{key}_cat_keep_sgram.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################\n",
    "## Save processing information to spectrogram H5\n",
    "###################################\n",
    "with h5py.File(SpecUFEx_H5_path,'a') as fileLoad:\n",
    "    \n",
    "    spec_parameters_group  = fileLoad.create_group(f\"spec_parameters\")\n",
    "    \n",
    "    spec_parameters_group.clear()\n",
    "\n",
    "    spec_parameters_group.create_dataset(name= 'fs', data=fs)\n",
    "    spec_parameters_group.create_dataset(name= 'lenData', data=lenData)\n",
    "    spec_parameters_group.create_dataset(name= 'nperseg', data=nperseg)\n",
    "    spec_parameters_group.create_dataset(name= 'noverlap', data=noverlap)\n",
    "    spec_parameters_group.create_dataset(name= 'nfft', data=nfft)\n",
    "    spec_parameters_group.create_dataset(name= 'mode', data=mode)\n",
    "    spec_parameters_group.create_dataset(name= 'scaling', data=scaling)\n",
    "    spec_parameters_group.create_dataset(name= 'fmin', data=fmin)\n",
    "    spec_parameters_group.create_dataset(name= 'fmax', data=fmax)\n",
    "    spec_parameters_group.create_dataset(name= 'tmin', data=tmin)\n",
    "    spec_parameters_group.create_dataset(name= 'tmax', data=tmax)    \n",
    "    spec_parameters_group.create_dataset(name= 'fSTFT', data=fSTFT)\n",
    "    spec_parameters_group.create_dataset(name= 'tSTFT', data=tSTFT)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3637"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evID_list_QC_sgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: SpecUFEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearize spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3637, 308, 200)\n",
      "100000 100000\n",
      "Running NMF\n",
      "Batch 0\n",
      "transforming NMF\n",
      "Running HMM\n",
      "Batch 0\n",
      "transforming HMM\n",
      "1893.879991054535  s elapsed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "X = []\n",
    "\n",
    "with h5py.File(SpecUFEx_H5_path,'a') as fileLoad:\n",
    "    for evID in fileLoad['spectrograms']:\n",
    "        specMat = fileLoad['spectrograms'].get(evID)[:]\n",
    "        X.append(specMat)\n",
    "\n",
    "    X = np.array(X)\n",
    "\n",
    "# ================\n",
    "print(np.shape(X))\n",
    "\n",
    "\n",
    "# print(X[:,:,-1])\n",
    "\n",
    "# # IOPub data rate exceeded.\n",
    "# # The notebook server will temporarily stop sending output\n",
    "# # to the client in order to avoid crashing it.\n",
    "# # To change this limit, set the config variable\n",
    "# # `--NotebookApp.iopub_data_rate_limit`.\n",
    "\n",
    "# # Current values:\n",
    "# # NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
    "# # NotebookApp.rate_limit_window=3.0 (secs)\n",
    "\n",
    "specparams = config[\"specufexParams\"]\n",
    "\n",
    "print(specparams[\"nmf_batchsz\"],specparams[\"hmm_batchsz\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%% ============================================================\n",
    "# Running SpecUFEx\n",
    "#%% ============================================================\n",
    "\n",
    "specparams = config[\"specufexParams\"]\n",
    "\n",
    "print('Running NMF')\n",
    "nmf = BayesianNonparametricNMF(X.shape)\n",
    "for i in range(specparams[\"nmf_nbatch\"]):\n",
    "    # pick random sample\n",
    "    print(f\"Batch {i}\")\n",
    "#     sample = np.random.choice(X.shape[0], specparams[\"nmf_batchsz\"])\n",
    "#     nmf.fit(X[sample], verbose=0)\n",
    "    nmf.fit(X, verbose=0)\n",
    "\n",
    "print('transforming NMF')    \n",
    "Vs = nmf.transform(X)\n",
    "# print how long it took\n",
    "\n",
    "#%%\n",
    "print('Running HMM')\n",
    "hmm = BayesianHMM(nmf.num_pat, nmf.gain)\n",
    "for i in range(specparams[\"hmm_nbatch\"]):\n",
    "    print(f\"Batch {i}\")\n",
    "#     sample = np.random.choice(Vs.shape[0], specparams[\"nmf_batchsz\"])\n",
    "    hmm.fit(Vs)\n",
    "\n",
    "print('transforming HMM')    \n",
    "fingerprints, As, gams = hmm.transform(Vs)\n",
    "\n",
    "# print(fingerprints[0])\n",
    "\n",
    "# show a fingerprint if you want to .. but not useful for running remotely..\n",
    "# plt.imshow(fingerprints[0])\n",
    "# plt.show()\n",
    "#%%\n",
    "\n",
    "endtime = time.time()\n",
    "\n",
    "time_elapsed = endtime - starttime\n",
    "\n",
    "\n",
    "os.system(\"say 'SpecUFEx complete'\")  \n",
    "print(time_elapsed, ' s elapsed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing all output to h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# save output to H5\n",
    "# =============================================================================\n",
    "print('writing all output to h5')\n",
    "with h5py.File(SpecUFEx_H5_path,'a') as fileLoad:\n",
    "\n",
    "\n",
    "    ##fingerprints are top folder\n",
    "    if 'fingerprints' in fileLoad.keys():\n",
    "        del fileLoad[\"fingerprints\"]\n",
    "    fp_group = fileLoad.create_group('fingerprints')\n",
    "\n",
    "    if 'SpecUFEX_output' in fileLoad.keys():\n",
    "        del fileLoad[\"SpecUFEX_output\"]\n",
    "    out_group = fileLoad.create_group(\"SpecUFEX_output\")\n",
    "\n",
    "    # write fingerprints: ===============================\n",
    "    for i, evID in enumerate(fileLoad['spectrograms']):\n",
    "        fp_group.create_dataset(name= evID, data=fingerprints[i])\n",
    "\n",
    "\n",
    "    # write the SpecUFEx out: ===========================\n",
    "    # maybe include these, but they are not yet tested.\n",
    "    ACM_group = fileLoad.create_group(\"SpecUFEX_output/ACM\")\n",
    "    STM_group = fileLoad.create_group(\"SpecUFEX_output/STM\")\n",
    "\n",
    "    for i, evID in enumerate(fileLoad['spectrograms']):\n",
    "        ACM_group.create_dataset(name=evID,data=Vs[i]) #ACM\n",
    "        STM_group.create_dataset(name=evID,data=gams[i]) #STM\n",
    "\n",
    "    gain_group = fileLoad.create_group(\"SpecUFEX_output/ACM_gain\")\n",
    "    W_group                      = fileLoad.create_group(\"SpecUFEX_output/W\")\n",
    "    EB_group                     = fileLoad.create_group(\"SpecUFEX_output/EB\")\n",
    "    ## # # delete probably ! gain_group                   = fileLoad.create_group(\"SpecUFEX_output/gain\")\n",
    "    #RMM_group                    = fileLoad.create_group(\"SpecUFEX_output/RMM\")\n",
    "\n",
    "    W_group.create_dataset(name='W',data=nmf.EW)\n",
    "    EB_group.create_dataset(name=evID,data=hmm.EB)\n",
    "    gain_group.create_dataset(name='gain',data=nmf.gain) #same for all data\n",
    "    # RMM_group.create_dataset(name=evID,data=RMM)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
